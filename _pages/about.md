---
permalink: /
title: "Zhenyu Hou"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am Zhenyu Hou, a PhD student in the [Department of Computer Science and Technology](https://www.cs.tsinghua.edu.cn/) at Tsinghua University. I am a member of [KEG](https://keg.cs.tsinghua.edu.cn/) and am advised by Prof. Yuxiao Dong and Prof. Jie Tang.

My current research focuses on:
- Graph machine learning
- Self-supervised learning
- Recommender systems and robust recommendation
- Large language models, reasoning, and agent systems

Project experiences
======
- Led post-training efforts for GLM models, with a focus on reasoning quality, alignment, and robust real-world behavior.
- **Project lead of the GLM-4.5 series models**, driving agentic capability design, evaluation, and iteration.
- Contributed to large-scale LLM training and iteration across GLM model generations.
- **GraphMAE / GraphMAE2 line (first author):** Built masked graph pretraining methods published at ICML 2022 and WWW 2023, with broad adoption in graph self-supervised learning.
- **T1 reasoning project (ICML 2025):** Contributed to reinforcement-learning and inference-scaling based reasoning improvements for large language models.
- **Recognition:** Recipient of the 2025 Ant Group Scholarship (10 awardees worldwide).

Education
======
- PhD student, Department of Computer Science and Technology, Tsinghua University (September 2021 - present)
- BEng, Computer Science and Technology, Tsinghua University (September 2017 - July 2021)

Selected publications
======
Most-cited first-author papers on Google Scholar:

1. **[HIGHLIGHT]** *GraphMAE: Self-Supervised Masked Graph Autoencoders* (ICML 2022, first author) [[GitHub]](https://github.com/THUDM/GraphMAE)
1. **[HIGHLIGHT]** *GraphMAE2: A Decoding-Enhanced Masked Self-Supervised Graph Learner* (WWW 2023, first author) [[GitHub]](https://github.com/THUDM/GraphMAE2)
1. *GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models* (arXiv 2025)
1. *T1: Advancing Language Model Reasoning through Reinforcement Learning and Inference Scaling* (ICML 2025)
1. *ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools* (arXiv 2024)
1. *Self-Supervised Attributed Graph Learning: A Comprehensive Review* (TKDE 2021)

Profiles
======
- Google Scholar: <https://scholar.google.com/citations?hl=zh-CN&oi=ao&user=44W9SfwAAAAJ>
- GitHub: <https://github.com/think2try>
- KEG: <https://keg.cs.tsinghua.edu.cn/>

References
======
- Yuxiao Dong homepage (student profile): <https://dongyx.github.io/>
- GraphMAE project page (Chinese web): <https://graphmae.github.io/>
